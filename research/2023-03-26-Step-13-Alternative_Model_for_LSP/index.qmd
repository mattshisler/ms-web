---
title: "Step 13 - An alternative Heirarchical Model for Spatial Land Surface Phenology - Pixel Climate Trends"
description: "Develop a streamlined analysis workflow to identify climate trends."
author:
  - name: Matthew Shisler
    affiliation: North Carloina State University - Department of Statistics
    affiliation-url: https://statistics.sciences.ncsu.edu/ 
date: "3/29/2023"
categories: [Bayesian, MCMC, Spatial, MCAR] # self-defined categories
draft: false 
format:
  html: 
    code-fold: false
execute: 
  cache: false
  freeze: false
---


```{r}
#| label: load-packages
#| output: false
#| code-summary: "Code: Load the packages"

library(tidyverse)
library(igraph)
library(viridis)
library(matrixsampling)
```

## Intro

Here we will develop the the full workflow for a spatial analysis of land-surface phenology (LSP) using a vegetation index (VI) constructed from remotely-sensed surface reflectance and emmitance.

Let $\mathcal{D}$ be a spatial domain partitioned into a regular lattice of $n$ areal units which we will refer to as "locations" or "pixels". Index these units by $s \in S,\, S = \{1,2,\dots,n\}$. 

For year $t \in T$, a satellite captures imagery from the earth's surface on a subset of days $\mathbf{d}_t \subset \{1, 2, \dots, m\}$ where $m$ may take on a value of 365 or 366. The choice of either does not appear to be consequential. 


Let $Y_{s,t,j} \in (0,1)$ be the vegetation index observed on day $d_{t,j}$ of year $t$ at pixel $s$. Though the VI is restricted to the interval $(0,1)$, we nevertheless adopt a Gaussian model with mean function $v(d;\boldsymbol\theta)$, parameterized by the $p \times 1$ vector $\boldsymbol\theta$, and variance $\sigma^2$ which corresponds to the random noise in the satellite measurements. The assumption is that the true mean is bounded sufficiently far from the physical limits of $0$ and $1$ and the random noise is small so that there is practically no scenario in which we would be required to model values of $0$ or $1$. Notationally,

$$
Y_{s,t,j} \sim \text{Normal}\left(v(d_{t,j};\boldsymbol\theta_{s,t}), \sigma^2\right)
$$
where $v(d;\boldsymbol{\theta}) : \mathbb{R} \rightarrow \mathbb{R}$ is the so-called double-logistic function,
$$
v(d; \boldsymbol{\theta}) = \theta_1 + (\theta_2 - \theta_7d)\left(\frac{1}{1 +\exp\left\{\frac{d - \theta_3}{\theta_5}\right\}} - \frac{1}{1 +\exp\left\{\frac{d - \theta_4}{\theta_6}\right\}}\right)
$$
The parameters of the double-logistic function are readily interpretable in a way that will be explained later.

At the first step in the analysis we aggregate the data over some pre-defined space and time domain whose "typical" or "average" phenological characteristics are to be estimated using a frequentist non-linear least squares regression. This amounts to estimating $\boldsymbol\theta$ for the aggregated data. Denote the estimate as $\widehat{\boldsymbol\theta}_{0}$. We then linearize the double-logistic function centered on $\widehat{\boldsymbol\theta}_{0}$,
$$
v(d;\boldsymbol\theta) \approx v(d; \widehat{\boldsymbol\theta}_0) + \nabla_{\boldsymbol\theta} v(d; \boldsymbol\theta)|_{\boldsymbol\theta = \widehat{\boldsymbol\theta}_0}(\boldsymbol\theta -\widehat{\boldsymbol\theta}_0)
$$

From this linearization we define the following,
$$
\begin{align*}
r_{s,t,j} &= Y_{s,t,j} - v(d_{t,j}, \widehat{\boldsymbol\theta}_0),\\
X_0(d) &=  \nabla_{\boldsymbol\theta} v(d; \boldsymbol\theta)|_{\boldsymbol\theta = \widehat{\boldsymbol\theta}_0},\\
\boldsymbol\delta_{s,t} &= \boldsymbol\theta_{s,t} - \widehat{\boldsymbol\theta}_0.
\end{align*}
$$
Here, $r_{s,t,j}$ are the residuals from the model of the domain's typical phenological characteristics, the gradient $X_0(d) : \mathbb{R} \rightarrow \mathbb{R}^p$ is regarded as a set of basis functions, and $\boldsymbol\delta_{s,t}$ represents the deviation in the phenological characteristics of pixel $s$ in year $t$ from the domain's typical characteristics, $\widehat{\boldsymbol\theta}_0$.

Next, we construct the $m \times p$ "parent" design matrix $\mathbf{X}_0$ with rows $X_0(d)$, $d = 1,2,\dots,m$. Then define the "child" design matrix $\mathbf{X}_{s,t}$ for each pixel-year pair $(s,t)$ by sub-setting the rows of $\mathbf{X}_0$ that correspond to the days $\mathbf{d}_t$ for which VI measurements were collected at pixel $s$.

This facilitates modeling through the residuals,
$$
\mathbf{r}_{s,t} \sim \text{Normal}\left(\mathbf{X}_{s,t}\boldsymbol\delta_{s,t}, \sigma^2\mathbf{I}\right)
$$
where $\mathbf{r}_{s,t}$ is the vector of residuals at pixel-year pair $(s,t)$ and $\mathbf{I}$ is an identity matrix of sufficient dimension, unspecified because the number of VI measurements vary across pixel-year pairs.

We have transformed the task of modeling a non-linear mean function, $v(d;\boldsymbol\theta)$, to modeling a linear mean function $\mathbf{X}\boldsymbol\delta$. A key assumption is that any specific pixel-year pair does not deviate substantially from the domain's typical phenological characteristics. Otherwise the linearization will produce a poor approximation to the original non-linear mean function.

If the goal of the analysis is to identify climate trends across pixels in the spatial domain as a function of other climatological factors, then we may consider collapsing this model into a more computationally manageable scheme.

We can construct the usual estimates for $\boldsymbol\delta_{s,t}$ and their corresponding variance, $\text{Var}(\widehat{\boldsymbol\delta}_{s,t})$, from our model of the residuals. These are of course,
$$
\widehat{\boldsymbol\delta}_{s,t} = \left(\mathbf{X}^T_{s,t}\mathbf{X}_{s,t}\right)^{-1}\mathbf{X}^T_{s,t}\mathbf{r}_{s,t} \quad \text{and} \quad \text{Var}(\widehat{\boldsymbol\delta}_{s,t}) = \sigma^2\left(\mathbf{X}^T_{s,t}\mathbf{X}_{s,t}\right)^{-1} = \sigma^2\boldsymbol{\mathcal{X}}^{-1}_{s,t}
$$
leaving $\sigma^2$ to be estimated later.

As a parenthetical note, we could go so far as to consider $\sigma^2$ fixed by using the results of research on the measurement noise associated with satellite sensors and atmospheric attenuation.

We may from time to time use an emperical estimate for the covariance of the deviation vectors. We construct these by collecting $\widehat{\boldsymbol\delta}_{s,t}$ over all spatial locations $s \in \mathcal{D}$ for each year $t \in T$, then computing the sample covariance matrix
$$
\widehat{\boldsymbol\Omega}_t = \frac{1}{n-1}\sum_{s=1}^n(\widehat{\boldsymbol\delta}_{s,t} - \bar{\widehat{\boldsymbol\delta}}_{\cdot,t})(\widehat{\boldsymbol\delta}_{s,t} - \bar{\widehat{\boldsymbol\delta}}_{\cdot,t})^T
$$
note: but we only assume conditional independence of $\widehat{\boldsymbol\delta}_{s,t}$, is this still okay to do?


From here we will consider a Bayesian hierarchical model incorporating climatological covariates, $\boldsymbol{\mathcal{Z}}_{s,t}$ for pixel-year pair $(s,t)$, and the associated spatial effects $\boldsymbol\beta_s$ on which we place a multivariate conditionally autoregressive (MCAR) prior with common propriety parameter $\rho$. 

We define $\mathbf{W}$ as the first-order neighborhood matrix for the spatial domain $\mathcal{D}$. The $s,s'$ entry of $\mathbf{W}$, $w_{s,s'}$ is $1$ if spatial locations $s$ and $s'$ are adjacent to one another and $0$ otherwise. The number of neighbors for location $s$ is the corresponding row sum of $\mathbf{W}$, $w_{s+}$.

The model is,
$$
\begin{align*}
\widehat{\boldsymbol{\delta}}_{s,t} &= \mathcal{Z}_{s,t}\boldsymbol\beta_{s} + \boldsymbol\epsilon_{s,t}\\
\boldsymbol\epsilon_{s,t} &\sim \text{MCAR}(\rho_\epsilon, \widehat{\boldsymbol\Omega}_t)\\
\\
\boldsymbol\beta_{s} &\sim \text{MCAR}(\rho_\beta, \boldsymbol\Lambda)\\
\boldsymbol\Lambda &\sim \text{InvWishart}(\nu, \mathbf{G})\\
\rho_\beta &\sim \text{Unif}(0,1)\\
\rho_\epsilon &\sim \text{Unif}(0,1)
\end{align*}
$$
where $\text{MCAR}(\rho, \boldsymbol\Lambda)$ represents the typical proper MCAR prior,
$$
\boldsymbol\beta_s \,|\, \boldsymbol\beta_{s' \ne s}, \boldsymbol\Lambda, \rho_\beta \sim \text{Normal}\left(\rho_\beta\sum_{s' \in \mathcal{N}(s)}\frac{w_{s,s'}}{w_{s+}}\boldsymbol\beta_{s'}, \frac{\boldsymbol\Lambda}{w_{s+}}\right)
$$
$$
\widehat{\boldsymbol\delta}_{s,t} \,|\, \widehat{\boldsymbol\delta}_{s' \ne s,t}, \, \widehat{\boldsymbol\Omega}_t, \rho_{\epsilon} \sim \text{Normal}\left(\boldsymbol{\mathcal{Z}}_{s,t}\boldsymbol\beta_s +\rho_{\epsilon}\sum_{s' \in \mathcal{N}(s)} \frac{w_{s,s'}}{w_{s+}}\left(\widehat{\boldsymbol{\delta}}_{s',t} - \boldsymbol{\mathcal{Z}}_{s',t}\boldsymbol\beta_{s'}\right), \frac{\widehat{\boldsymbol{\Omega}}_t}{w_{s+}} \right)
$$



The full conditionals for this model are:

$$
\begin{align*}
\boldsymbol\beta_s \,|\, \text{rest} &\sim \text{Normal}\left(\mathbf{V}^{-1}_{\beta_s}\mathbf{M}_{\beta_s}, \mathbf{V}^{-1}_{\beta_s}\right)\\
\mathbf{V}_{\beta_s} &= \sum_{t\in T}\boldsymbol{\mathcal{Z}}^T_{s,t}\widehat{\boldsymbol\Omega}^{-1}_{t}\boldsymbol{\mathcal{Z}}_{s,t} + w_{s+}\boldsymbol\Lambda^{-1}\\
\mathbf{M}^T_{\beta_s} &= \rho_{\epsilon}\sum_{t\in T} \left[\left(\sum_{s' \in \mathcal{N}(s)}w_{s,s'}\left(\widehat{\boldsymbol\delta}^T_{s',t} - \boldsymbol\beta^T_{s'}\boldsymbol{\mathcal{Z}}^T_{s',t}\right) + w_{s+}\widehat{\boldsymbol\delta}^T_{s,t}\right)\widehat{\boldsymbol\Omega}^{-1}_t \boldsymbol{\mathcal{Z}}^T_{s,t}\right] + \rho_{\beta}\sum_{s' \in \mathcal{N}(s)} w_{s,s'}\boldsymbol\beta^T_{s'}\boldsymbol\Lambda^{-1}\\
\\\\
\mathbf{M}_{\beta_s} &= \rho_{\epsilon}\sum_{t\in T} \left[\ \boldsymbol{\mathcal{Z}}_{s,t}\widehat{\boldsymbol\Omega}^{-1}_t\left(\sum_{s' \in \mathcal{N}(s)}w_{s,s'}\left(\widehat{\boldsymbol\delta}_{s',t} - \boldsymbol{\mathcal{Z}}_{s',t}\boldsymbol\beta_{s'}\right) + w_{s+}\widehat{\boldsymbol\delta}_{s,t}\right)\right] + \rho_{\beta}\boldsymbol\Lambda^{-1}\sum_{s' \in \mathcal{N}(s)} w_{s,s'}\boldsymbol\beta_{s'}\\
\\\\
\mathbf{M}_{\beta_s} &= \rho_{\epsilon}\sum_{t\in T} \left[\ \boldsymbol{\mathcal{Z}}_{s,t}\widehat{\boldsymbol\Omega}^{-1}_t\left(\sum_{s' \in \mathcal{N}(s)}\left(\widehat{\boldsymbol\delta}_{s',t} - \boldsymbol{\mathcal{Z}}_{s',t}\boldsymbol\beta_{s'}\right) + w_{s+}\widehat{\boldsymbol\delta}_{s,t}\right)\right] + \rho_{\beta}\boldsymbol\Lambda^{-1}\sum_{s' \in \mathcal{N}(s)} \boldsymbol\beta_{s'}\\
\\\\
\boldsymbol\Lambda \,|\, \text{rest} &\sim \text{InvWishart}\left(\nu + n, \mathbf{G} + \mathbf{H}\right)\\
n &= \text{number of pixels}\\
\mathbf{H} &= \mathbf{B}^T(\mathbf{D}-\rho\mathbf{W})\mathbf{B}\\
\end{align*}
$$
Here $\mathbf{B}$ is a matrix with rows eaual to $\boldsymbol\beta^T_s$ (different than how it was defined $\mathbf{B}$ in previous posts) and $\mathbf{D}$ is a diagonal matrix of the row sums from $\mathbf{W}$.

Further, $n = |S|$, the number of pixels, and $k = |T|$, the number of years.

Though we defined the elements of the neighborhood matrix, $\mathbf{W}$, to be either $0$ or $1$, we've elected to keep them in the derivation of the full conditional

We will simulate data from this model, then try to fit the model using MCMC.

```{r}
# specify spatial domain

n <- 50^2
spat_domain <- expand.grid(x = 1:sqrt(n), y = 1:sqrt(n))
spat_domain$label <- 1:n

spat_domain_g <- make_lattice(c(sqrt(n),sqrt(n)), mutual = TRUE)
W <- as_adjacency_matrix(spat_domain_g, sparse=0)
D <- diag(rowSums(W))
```


Sample beta for each site. Here we set $p = 2$, $q = 2$, and assume the elements of $\boldsymbol\beta_s$ to be independent normal with mean $\mu=0$ and constant variance $\sigma^2 = 3$. Finally, we will set $k=10$ years.

Should I actually sample these from an MCAR distribution? Not sure.

```{r}
#| eval: false

p = 2 
q = 2  
k = 1

# propriety parameter for epsilon MCAR
rho_eps <- 0.99

# Conditional Covariance Matrix.
# Assume Omega_t is constant across time for now.
Omega <- matrix(c(1, 0.2,
                   0.2, 1), byrow = T, ncol = p)

# Construct MCAR joint distribution covariance
inv_Sigma_eps <- kronecker((D-rho_eps*W), solve(Omega))

# Draw from eps ~ MCAR(rho_eps, Omega_t = Omega)
# eps array is 3-dim - left to right: response length, time, spatial index.
eps <- array(NA, dim = c(p,k,n))
for (t in 1:k){  
  eps[,t,] <- t(matrix(backsolve(chol(inv_Sigma_eps), rnorm(n*p)), byrow=T, ncol=p))
}

# propriety parameter for beta MCAR
rho_beta <- 0.99

# Conditional Covariance Matrix
# beta_s is regarded as a vector of stacked beta_1, beta_2 vectors
# Assume beta_1 and beta_2 vectors are independent for now.
Lambda <- 10*matrix(c(  1, 0.9,   0,   0,
                   0.9,   1,   0,   0,
                     0,   0,   1, 0.9,
                     0,   0, 0.9,   1 ), byrow = T, ncol = p*q)

# Construct MCAR joint distribution covariance
inv_Sigma_beta <- kronecker((D-rho_beta*W), solve(Lambda))

# Draw from beta ~ MCAR(rho_beta, Lambda)
# beta array is 3-dim - left to right: p, q, spatial index
# note: the beta_s vectors are drawn in joint vectorized form.
#       first, split the joint vector according to spatial index
#       second, collapse the (p*q x 1) vectors into (p x q) matrices
beta_temp <- t(matrix(backsolve(chol(inv_Sigma_eps), rnorm(n*p*q)), byrow=T, ncol=p*q))
beta <- array(NA, dim = c(p,q,n))
beta[1:p,1:q,] <- beta_temp
rm(beta_temp)


# sample covariates
# For now, sample covariates from a normal distribution.
# Consider changing in the future.
# Z array is 3 dim - left to right: time, covariate vector length, spatial index
Z <- array(NA, dim=c(k,q,n))
for (s in 1:n){
  Z[,,s] <- matrix(c(rep(1,k),rnorm(k,0,1)), ncol = q)
}

# Now draw delta (naively via loops)
# delta array is 3-dim - left to right: response vector length, time, space
delta <- array(NA, dim = c(p,k,n))
for (s in 1:n){
  for (t in 1:k){
    delta[,t,s] <- Z[t,,s]%*%beta[,,s] + eps[,t,s]
  }
}
```

Add the data to the spatial domain data frame.

```{r}
#| eval: false
# For now, column by column
spat_domain_temp <- spat_domain

spat_domain <- cbind(spat_domain_temp, matrix(t(delta[1,,]),ncol=k), matrix(t(delta[2,,]),ncol=k))


colnames(spat_domain)[4:(3+2*k)] <- c(paste0("delta_1_s_",seq(1:k)),paste0("delta_2_s_",seq(1:k)))

test <- pivot_longer(spat_domain, cols = starts_with("delta"), names_to = "delta_i_t", values_to = "response")
```

Let's observe some plots:

```{r}
#| eval: false
ggplot(spat_domain) +
  geom_tile(aes(x, y, fill=delta_2_s_1)) +
  scale_y_reverse() +
  scale_fill_gradientn(colors = viridis(10)) +
  coord_fixed() + 
  theme_void()

ggplot(test) +
  geom_tile(aes(x, y, fill=response)) +
  scale_y_reverse() +
  scale_fill_gradientn(colors = viridis(10)) +
  coord_fixed() + 
  theme_void() + 
  facet_wrap(vars(delta_i_t))

```

Okay, we have the data. Now we want to code the MCMC sampler.
We'll begin with $\rho_\epsilon$ and $\rho_\beta$ fixed. This way we can focus
on the full conditionals for $\beta_s$ and $\Lambda$.












