---
title: "Step 21 - Full Simulation of EVI2 (spatial included)"
description: "TBD"
author:
  - name: Matthew Shisler
    affiliation: North Carloina State University - Department of Statistics
    affiliation-url: https://statistics.sciences.ncsu.edu/ 
date: "7/3/2023"
categories: [Bayesian, MCMC, Spatial, MCAR] # self-defined categories
draft: true 
format:
  html: 
    code-fold: false
execute: 
  eval: false
  freeze: false
---


```{r}
#| label: load-packages
#| output: false
#| code-summary: "Code: Load the packages"
#| code-fold: true
#| message: false
#| warning: false

library(tidyverse)
library(igraph)
library(viridis)
library(matrixsampling)
library(MCMCpack)
library(gridExtra)
library(extraDistr)
library(tictoc)
library(minpack.lm)
library(terra)
library(ncdf4)
library(numDeriv)
library(MASS)
library(lubridate)
```

```{r}
# specify spatial domain

n <- 10^2
spat_domain <- expand.grid(x = 1:sqrt(n), y = 1:sqrt(n))
spat_domain$label <- 1:n

spat_domain_g <- make_lattice(c(sqrt(n),sqrt(n)), mutual = TRUE)
W <- as_adjacency_matrix(spat_domain_g, sparse=0)
D <- diag(rowSums(W))

```

```{r}
p = 6 
q = 2  
k = 20

# propriety parameter for epsilon MCAR
rho_eps <- 0.95

# Conditional Covariance Matrix.
# Assume Omega_t is constant across time for now.
# first, specify desired correlation and std deviation, then construct covariance matrix.
cOmega <- diag(p) # independent


stddev_eps <- rep(1,p)

Omega <- diag(stddev_eps)%*%cOmega%*%diag(stddev_eps)

# Construct MCAR joint distribution covariance
inv_Sigma_eps <- kronecker((D-rho_eps*W), solve(Omega))

# Draw from eps ~ MCAR(rho_eps, Omega_t = Omega)
# eps array is 3-dim - left to right: response length, time, spatial index.
eps <- array(NA, dim = c(p,k,n))
for (t in 1:k){  
  eps[,t,] <- t(matrix(backsolve(chol(inv_Sigma_eps), rnorm(n*p)), byrow=T, ncol=p))
} 

```


```{r}
display_ls <- vector(mode = "list", length = k)

for (t in 1:k){
  temp <- spat_domain
  temp$eps1 <- eps[1,t,]
  temp$eps2 <- eps[2,t,]
  temp$eps3 <- eps[3,t,]
  temp$eps4 <- eps[4,t,]
  temp$eps5 <- eps[5,t,]
  temp$eps6 <- eps[6,t,]
  temp$year <- rep(t, n)
  display_ls[[t]] <- temp 
}

display_df <- do.call(rbind, display_ls)

panel_names <- as_labeller(function(x) paste('t =', x))

ggplot(display_df) +
            geom_tile(aes(x, y, fill=eps1)) +
            scale_y_reverse() +
            scale_fill_gradientn(colors = viridis(10),
                                 limits = c(min(display_df$eps1),max(display_df$eps1)),
                                 name = bquote("\u03F5"["s,t,1"])) +
            coord_fixed() + 
            theme_void() + 
            facet_wrap(~year, labeller = panel_names)

```

```{r}
# propriety parameter for beta MCAR
rho_beta <- 0.99

# Conditional Covariance Matrix
# beta_s is regarded as a vector of stacked beta_1, beta_2 vectors
# Assume beta_1 and beta_2 vectors are independent for now.

# cLambda <- diag(p*q)
# 
# cLambda <- matrix(c(  1,   0,   0,   0,
#                       0,   1,   0,   0,
#                       0,   0,   1, 0.7,
#                       0,   0, 0.7,   1 ), byrow = T, ncol = p*q)

cLambda <- diag(p*q)

        
stddev_beta <- diag(rep(c(2,4), each = p))

Lambda <- stddev_beta%*%cLambda%*%stddev_beta

# Construct MCAR joint distribution covariance
inv_Sigma_beta <- kronecker((D-rho_beta*W), solve(Lambda))

# Draw from beta ~ MCAR(rho_beta, Lambda)
# beta array is 3-dim - left to right: p, q, spatial index
# note: the beta_s vectors are drawn in joint vectorized form.
#       first, split the joint vector according to spatial index
#       second, collapse the (p*q x 1) vectors into (p x q) matrices


beta_mat <- t(matrix(backsolve(chol(inv_Sigma_beta), rnorm(n*p*q)), byrow=T, ncol=p*q))
# For now assume zero mean.
# beta_mat[1,] <- 0
# beta_mat[2,] <- 0

# construct array version of beta
beta_arr <- array(NA, dim = c(p,q,n))
beta_arr[1:p,1:q,] <- beta_mat
```

```{r}
display_ls <- vector(mode = "list", length = (p*q))

idx <- 1
for (i in 1:p){
  for (j in 1:q){
    temp <- spat_domain
    temp$beta <- beta_arr[i,j,]
    temp$p <- rep(i, n)
    temp$q <- rep(j, n)
    display_ls[[idx]] <- temp
    idx <- idx + 1
  }
}

display_df <- do.call(rbind, display_ls)

my_plot <- function(data) {
  
  ggplot(data) +
  geom_tile(aes(x, y, fill=beta)) +
  scale_y_reverse() +
  scale_fill_gradientn(colors = viridis(10), name = bquote(beta[.(unique(data$q)) * "," * .(unique(data$p))])) +
  coord_fixed() + 
  theme_void()
  
}

do.call(grid.arrange, 
        args=list(grobs=by(display_df, list(display_df$p, display_df$q), my_plot), 
                  ncol=q,
                  top="",
                  as.table = F))
```

```{r}
# sample covariates
# For now, the only covariate is time in years, centered and scaled.
# Consider changing in the future.
# Z array is 3 dim - left to right: time, covariate vector length, spatial index
Z <- array(NA, dim=c(k,q,n))
for (s in 1:n){
  #Z[,,s] <- matrix(c(rep(1,k),rnorm((q-1)*k,0,1)), ncol = q)
  Z[,,s] <- matrix(c(rep(1,k), scale(1:k, scale = F)), ncol = q)
}

# Rather than sampling covariates from a normal distribution, let's
# let's just focus on an intercept term and centered equally spaced term.


# Now draw delta (naively via loops)
# delta array is 3-dim - left to right: response vector length, time, space
delta <- array(NA, dim = c(p,k,n))
for (s in 1:n){
  for (t in 1:k){
    delta[,t,s] <- beta_arr[,,s]%*%Z[t,,s] + eps[,t,s]
  }
}

```

```{r}
display_ls <- vector(mode = "list", length = k)

for (t in 1:k){
  temp <- spat_domain
  temp$eps1 <- eps[1,t,]
  temp$eps2 <- eps[2,t,]
  temp$eps3 <- eps[3,t,]
  temp$eps4 <- eps[4,t,]
  temp$eps5 <- eps[5,t,]
  temp$eps6 <- eps[6,t,]
  temp$delta1 <- delta[1,t,] 
  temp$delta2 <- delta[2,t,]
  temp$delta3 <- delta[3,t,] 
  temp$delta4 <- delta[4,t,]
  temp$delta5 <- delta[5,t,] 
  temp$delta6 <- delta[6,t,]
  temp$year <- rep(t, n)
  display_ls[[t]] <- temp 
}

display_df <- do.call(rbind, display_ls)

panel_names <- as_labeller(function(x) paste('t =', x))

ggplot(display_df) +
            geom_tile(aes(x, y, fill=delta1)) +
            scale_y_reverse() +
            scale_fill_gradientn(colors = viridis(10),
                                 limits = c(min(display_df$delta1),max(display_df$delta1)),
                                 name = bquote(delta["s,t,1"])) +
            coord_fixed() + 
            theme_void() + 
            facet_wrap(~year, labeller = panel_names)

```

```{r}
niters <- 2000
burn   <- 2000
# burn   <- 0.1*niters

# storage
keep_beta_mat <- array(0, dim = c(p*q, n, niters))
keep_Lambda   <- array(0, dim = c(p*q, p*q, niters))
keep_rho_eps  <- rep(0, niters) 
keep_rho_beta <- rep(0, niters)

# initial values
mc_beta_mat <- beta_mat
mc_beta_mat <- matrix(10, nrow = p*q, ncol = n)
mc_beta_arr <- beta_arr
mc_beta_arr[1:p,1:q,] <- mc_beta_mat
mc_Lambda   <- diag(p*q)
mc_rho_eps  <- 0.5
mc_rho_beta <- 0.5
keep_beta_mat[,,1] <- mc_beta_mat
keep_Lambda[,,1] <- mc_Lambda
keep_rho_eps[1] <- mc_rho_eps
keep_rho_beta[1] <- mc_rho_beta


# prior parameters
nu <- p*q - 1 + 0.1 # come back to check this
G  <- diag(p*q)

# M-H tuning parameters
MH_beta <- 0.1
att_beta <- 0
acc_beta <- 0

MH_eps  <- 0.1
att_eps <- 0
acc_eps <- 0

```


```{r}
# tic()
# Omega is constant in time for now. May need to update this to
# consider different Omegas for each year.
inv_Omega <- solve(Omega)
inv_Omega_arr <- array(rep(c(inv_Omega), k), dim = c(p,p,k))

# Pre-compute the first summation term for V in the full conditional for beta.
sumt_ZT_Omega_inv_Z <- array(0, dim = c(p*q, p*q, n))
for (s in 1:n){
  for (j in 1:k){
    sumt_ZT_Omega_inv_Z[,,s] <- sumt_ZT_Omega_inv_Z[,,s] +
                                t(kronecker(t(Z[j,,s]),diag(p)))%*%inv_Omega_arr[,,j]%*%kronecker(t(Z[j,,s]), diag(p))
  }
}

# collect the neighbor indices for use within the sampling loop
neighbor_idx     <- apply(W, MARGIN = 1, function(x) which(x==1))
neighbor_weights <- lapply(1:n, function(x) W[x, neighbor_idx[[x]]])


# Pre-compute the number of neighbors for each pixel.
w_plus <- rowSums(W)
D <- diag(w_plus)

# pre-compute residuals for the first iteration.
Bz <- delta
for (j in 1:k){
  for (s in 1:n){
    Bz[,j,s] <- mc_beta_arr[,,s]%*%Z[j,,s]
  }
}
resid <- delta - Bz

# loglike functions for Metropolis-Hastings steps
rho_beta_loglike <- function(rho, beta_mat, neighbor_idx, neighbor_weights, w_plus, inv_Lambda){
  
  temp1 <- 0
  temp2 <- 0
  for (s in 1:n){
    beta_tilde <- (beta_mat[,neighbor_idx[[s]]]%*%neighbor_weights[[s]])/w_plus[s]
    temp1 <- temp1 + w_plus[s]*(t(beta_tilde)%*%inv_Lambda%*%beta_tilde) 
    temp2 <- temp2 + w_plus[s]*(t(beta_mat[,s])%*%inv_Lambda%*%beta_tilde)
  }
  return(-0.5*((rho^2)*temp1 - 2*rho*temp2))
  
}

rho_eps_loglike <- function(rho, delta, Bz, resid, inv_Omega_arr, neighbor_idx, neighbor_weights, w_plus){

  dbz <- delta + Bz
  
  temp1 <- 0
  temp2 <- 0
  for (s in 1:n){
    for (t in 1:k){
      r <- resid[,t,neighbor_idx[[s]]]%*%neighbor_weights[[s]]
      
      temp1 <- temp1 + (t(r)%*%inv_Omega_arr[,,t]%*%r)/w_plus[s]
      temp2 <- temp2 + (t(delta[,t,s]) - t(Bz[,t,s]))%*%inv_Omega_arr[,,t]%*%r
    }
  }
  
  return(-0.5*((rho^2)*temp1 - 2*rho*temp2))
}

```

```{r}
tic()
# profvis({
for (iter in 2:niters){
  
  # computing residuals needed in full conditional for beta - M.
  # probably a better way to do this.
  
  inv_mc_Lambda <- solve(mc_Lambda)
  
  # sample beta_s
  for (s in 1:n){
    
    V <- w_plus[s]*sumt_ZT_Omega_inv_Z[,,s] + w_plus[s]*inv_mc_Lambda
    
    # revisit for efficiency
    temp <- 0
    for (j in 1:k){
      temp <- temp + t(kronecker(t(Z[j,,s]),diag(p)))%*%inv_Omega_arr[,,j]%*%(mc_rho_eps*resid[,j,neighbor_idx[[s]]]%*%neighbor_weights[[s]] +w_plus[s]*delta[,j,s])
       
    }
    M <- temp + mc_rho_beta*(inv_mc_Lambda%*%(mc_beta_mat[,neighbor_idx[[s]]]%*%neighbor_weights[[s]]))
      
    V_inv <- chol2inv(chol(V))
    mc_beta_mat[,s]  <- V_inv%*%M+t(chol(V_inv))%*%rnorm(p*q)
    # mc_beta_mat[,s]  <- beta_mat[,s]
    
  }
  mc_beta_arr[1:p,1:q,] <- mc_beta_mat
  
  # sample Lambda
  H <- mc_beta_mat%*%(D - mc_rho_beta*W)%*%t(mc_beta_mat)
  mc_Lambda <- MCMCpack::riwish(nu + n, G + H)
  # mc_Lambda <- Lambda
  
  # compute residuals
  Bz <- delta
  for (j in 1:k){
    for (s in 1:n){
      Bz[,j,s] <- mc_beta_arr[,,s]%*%Z[j,,s]
    }
  }
  resid <- delta - Bz
  
  
  # sample rho_eps
  att_eps <- att_eps + 1
  can <- rtnorm(1, mc_rho_eps, MH_eps, a = 0, b = 1)
  R   <- rho_eps_loglike(can,        delta, Bz, resid, inv_Omega_arr, neighbor_idx, neighbor_weights, w_plus) - # Likelihood
         rho_eps_loglike(mc_rho_eps, delta, Bz, resid, inv_Omega_arr, neighbor_idx, neighbor_weights, w_plus) +
         dtnorm(mc_rho_eps, mean = can        , sd = MH_eps, a = 0, b = 1, log = T) -      # M-H adjustment
         dtnorm(can,        mean = mc_rho_eps , sd = MH_eps, a = 0, b = 1, log = T)
  if(log(runif(1)) < R){
    acc_eps <- acc_eps + 1
    mc_rho_eps  <- can
  }
  #mc_rho_eps <- rho_eps
  
  # sample rho_beta
  att_beta <- att_beta + 1
  can <- rtnorm(1, mc_rho_beta, MH_beta, a = 0, b = 1)
  R   <- rho_beta_loglike(can,         mc_beta_mat, neighbor_idx, neighbor_weights, w_plus, inv_mc_Lambda) - # Likelihood
         rho_beta_loglike(mc_rho_beta, mc_beta_mat, neighbor_idx, neighbor_weights, w_plus, inv_mc_Lambda) +
         dtnorm(mc_rho_beta, mean = can         , sd = MH_beta, a = 0, b = 1, log = T) -      # M-H adjustment
         dtnorm(can,         mean = mc_rho_beta , sd = MH_beta, a = 0, b = 1, log = T)
  if(log(runif(1)) < R){
    acc_beta <- acc_beta + 1
    mc_rho_beta  <- can
  }
  #mc_rho_beta <- rho_beta
  
  # tuning
  if(iter < burn){
    if(att_eps > 100){
      if(acc_eps/att_eps < 0.3){MH_eps <- MH_eps*0.8}
      if(acc_eps/att_eps > 0.5){MH_eps <- MH_eps*1.2}
      acc_eps <- att_eps <- 0
    }
  }
  
  if(iter < burn){
    if(att_beta > 100){
      if(acc_beta/att_beta < 0.3){MH_beta <- MH_beta*0.8}
      if(acc_beta/att_beta > 0.5){MH_beta <- MH_beta*1.2}
      acc_beta <- att_beta <- 0
    }
  }
  
  
  keep_beta_mat[,,iter] <- mc_beta_mat 
  keep_Lambda[,,iter]   <- mc_Lambda
  keep_rho_eps[iter]    <- mc_rho_eps
  keep_rho_beta[iter]   <- mc_rho_beta
}
# })
toc()

```

```{r}
s <- 1
burn <- 100
beta_subscripts <- c("1,1", "1,2", "2,1", "2,2")

par(mfcol = c(2,2))
for (i in 1:(p*q)){
  tsub <- beta_subscripts[i]
  plot(burn:niters, 
       keep_beta_mat[i,s,burn:niters], 
       type = "l",
       xlab = "iteration",
       ylab = bquote(beta[.(tsub)]),
       ylim = c(min(min(keep_beta_mat[i,s,burn:niters]),beta_mat[i,s]), max(max(keep_beta_mat[i,s,burn:niters]),beta_mat[i,s])))
  abline(h = beta_mat[i,s], col = "red")
}
mtext(paste("Pixel: ",s), side = 3, line = -3, outer = TRUE)
```

```{r}
burn <- 50

location_sample <- sample(1:n, size = 5)

beta_subscripts <- c("1,1", "1,2", "2,1", "2,2")

for (s in location_sample){
  par(mfcol = c(2,2))
  for (i in 1:(p*q)){
    tsub <- beta_subscripts[i]
    plot(burn:niters, 
         keep_beta_mat[i,s,burn:niters], 
         type = "l",
         xlab = "iteration",
         ylab = bquote(beta[.(tsub)]),
         ylim = c(min(min(keep_beta_mat[i,s,burn:niters]),beta_mat[i,s]), max(max(keep_beta_mat[i,s,burn:niters]),beta_mat[i,s])))
    abline(h = beta_mat[i,s], col = "red")
  }
  mtext(paste("Pixel: ",s), side = 3, line = -3, outer = TRUE)
}




```

```{r}
burn <- 1
par(mfrow = c(2,2))

# off-diagonal
for (i in 1:(p*q)){
  for (j in i:(p*q)){
    tsub <- paste0(i,j)
    plot(burn:niters, 
         keep_Lambda[i,j,burn:niters], 
         type = "l",
         xlab = "iteration",
         ylab = bquote(Lambda[.(tsub)]))
    abline(h = Lambda[i,j], col = "red")
  }
  mtext(bquote(Lambda ~ "Matrix"), side = 3, line = -3, outer = TRUE)
}

```


```{r}
burn <- 1
par(mfrow=c(1,2))

plot(burn:niters, 
         keep_rho_beta[burn:niters], 
         type = "l",
         xlab = "iteration",
         ylab = bquote(rho[beta]))
    abline(h = rho_beta, col = "red")

plot(burn:niters, 
         keep_rho_eps[burn:niters], 
         type = "l",
         xlab = "iteration",
         ylab = bquote(rho["\u03F5"]))
    abline(h = rho_eps, col = "red")
```

